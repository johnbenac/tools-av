#!/usr/bin/env python3
"""
av-editor - Multi-source timeline editor with clapboard sync

Synchronizes video and audio from multiple sources using clapboard
timestamps, with per-source timelines for z-index based compositing.
"""

import argparse
import json
import os
import subprocess
import sys
import tempfile
from pathlib import Path

VERSION = "0.2.0"


class AVEditorError(Exception):
    """Base exception for av-editor errors"""
    pass


def run_command(cmd, verbose=False, dry_run=False):
    """Run a command and return output"""
    if verbose or dry_run:
        # Format command for readability
        cmd_str = ' '.join(cmd)
        if len(cmd_str) > 120:
            print(f"[CMD] {cmd_str[:120]}...")
        else:
            print(f"[CMD] {cmd_str}")

    if dry_run:
        return None

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=True
        )
        return result.stdout.strip()
    except subprocess.CalledProcessError as e:
        raise AVEditorError(f"Command failed: {' '.join(cmd)}\n{e.stderr}")


def probe_duration(file_path, stream_type=None, verbose=False):
    """Get duration of a file, trying stream duration first then format"""
    if stream_type:
        cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', f'{stream_type}:0',
            '-show_entries', 'stream=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            str(file_path)
        ]
        try:
            output = run_command(cmd)
            if output and output != 'N/A':
                dur = float(output)
                if dur > 0:
                    if verbose:
                        print(f"[INFO] {Path(file_path).name}: {stream_type} stream duration = {dur:.3f}s")
                    return dur
        except (ValueError, AVEditorError):
            pass

    # Fallback to format duration
    cmd = [
        'ffprobe', '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        str(file_path)
    ]
    output = run_command(cmd)
    if output and output != 'N/A':
        dur = float(output)
        if verbose:
            print(f"[INFO] {Path(file_path).name}: format duration = {dur:.3f}s")
        return dur

    raise AVEditorError(f"Could not determine duration for {file_path}")


def probe_resolution(file_path, verbose=False):
    """Get video resolution (width, height)"""
    cmd = [
        'ffprobe', '-v', 'error',
        '-select_streams', 'v:0',
        '-show_entries', 'stream=width,height',
        '-of', 'json',
        str(file_path)
    ]
    output = run_command(cmd)
    data = json.loads(output)
    if 'streams' in data and data['streams']:
        stream = data['streams'][0]
        width = stream.get('width')
        height = stream.get('height')
        if width and height:
            return (width, height)

    raise AVEditorError(f"Could not determine resolution for {file_path}")


def validate_file(file_path):
    """Check file exists and is readable"""
    p = Path(file_path)
    if not p.exists():
        raise AVEditorError(f"File not found: {file_path}")
    if not p.is_file():
        raise AVEditorError(f"Not a file: {file_path}")
    if not os.access(p, os.R_OK):
        raise AVEditorError(f"File not readable: {file_path}")


def load_config(config_path):
    """Load and validate JSON config file"""
    validate_file(config_path)

    with open(config_path, 'r') as f:
        try:
            config = json.load(f)
        except json.JSONDecodeError as e:
            raise AVEditorError(f"Invalid JSON in {config_path}: {e}")

    # Validate required fields
    if 'master_audio' not in config:
        raise AVEditorError("Config missing 'master_audio' section")

    ma = config['master_audio']
    if 'file' not in ma:
        raise AVEditorError("master_audio missing 'file'")
    if 'clap_time' not in ma:
        raise AVEditorError("master_audio missing 'clap_time'")

    if 'video_sources' not in config or not config['video_sources']:
        raise AVEditorError("Config missing 'video_sources' (need at least one)")

    # Validate video_sources is a dict with named sources
    if not isinstance(config['video_sources'], dict):
        raise AVEditorError("video_sources must be an object with named sources")

    for name, vs in config['video_sources'].items():
        if 'file' not in vs:
            raise AVEditorError(f"video_sources.{name} missing 'file'")
        if 'clap_time' not in vs:
            raise AVEditorError(f"video_sources.{name} missing 'clap_time'")
        if 'z_index' not in vs:
            raise AVEditorError(f"video_sources.{name} missing 'z_index'")

        # Validate timeline if present
        if 'timeline' in vs:
            if not isinstance(vs['timeline'], list):
                raise AVEditorError(f"video_sources.{name}.timeline must be an array")
            for i, event in enumerate(vs['timeline']):
                if 'at' not in event:
                    raise AVEditorError(f"video_sources.{name}.timeline[{i}] missing 'at'")
                if 'z_index' not in event:
                    raise AVEditorError(f"video_sources.{name}.timeline[{i}] missing 'z_index'")

    if 'production' not in config:
        raise AVEditorError("Config missing 'production' section")

    prod = config['production']
    if 'output_file' not in prod:
        raise AVEditorError("production missing 'output_file'")
    if 'start_offset' not in prod:
        raise AVEditorError("production missing 'start_offset'")
    if 'end_offset' not in prod:
        raise AVEditorError("production missing 'end_offset'")

    return config


def build_z_timeline(sources, master_clap, production_start, production_duration):
    """
    Build a complete z-index timeline for all sources.

    Timeline events are specified in master audio absolute time, but we convert
    them to production-relative time (0 = production start).

    Returns a list of (timestamp, {source_name: z_index}) representing
    all z-index changes across all sources.
    """
    # Collect all timeline events from all sources
    events = []

    for name, src in sources.items():
        default_z = src['z_index']

        # Add initial state at t=0
        events.append({
            'at': 0.0,
            'source': name,
            'z_index': default_z
        })

        # Add timeline events if present
        if 'timeline' in src:
            for event in src['timeline']:
                # Convert from master audio absolute time to production-relative time
                # Timeline event 'at' is offset from clap
                absolute_time = master_clap + float(event['at'])
                production_relative_time = absolute_time - production_start

                # Only include events within production range
                if 0 <= production_relative_time <= production_duration:
                    events.append({
                        'at': production_relative_time,
                        'source': name,
                        'z_index': event['z_index']
                    })

    # Sort by timestamp
    events.sort(key=lambda e: e['at'])

    # Build state changes
    current_state = {name: src['z_index'] for name, src in sources.items()}
    timeline = [(0.0, dict(current_state))]

    for event in events:
        if event['at'] == 0.0:
            # Already handled in initial state
            continue

        # Update state
        current_state[event['source']] = event['z_index']

        # Add state snapshot
        timeline.append((event['at'], dict(current_state)))

    return timeline


def render(args):
    """Render synchronized output from config"""
    config = load_config(args.config)
    verbose = args.verbose

    master = config['master_audio']
    master_file = master['file']
    master_clap = float(master['clap_time'])

    validate_file(master_file)
    master_duration = probe_duration(master_file, stream_type='a', verbose=verbose)

    print(f"Master audio: {master_file}")
    print(f"  Duration: {master_duration:.3f}s")
    print(f"  Clap at: {master_clap:.3f}s")

    # Process video sources
    video_sources = config['video_sources']
    source_info = {}

    print(f"\nVideo sources:")
    for name, src in video_sources.items():
        file_path = src['file']
        clap_time = float(src['clap_time'])
        default_z = src['z_index']

        validate_file(file_path)
        duration = probe_duration(file_path, stream_type='v', verbose=verbose)
        width, height = probe_resolution(file_path, verbose=verbose)

        # Calculate sync offset
        offset = master_clap - clap_time

        source_info[name] = {
            'file': file_path,
            'clap_time': clap_time,
            'duration': duration,
            'width': width,
            'height': height,
            'offset': offset,
            'default_z': default_z,
            'timeline': src.get('timeline', [])
        }

        print(f"  [{name}] {Path(file_path).name}")
        print(f"    Resolution: {width}x{height}")
        print(f"    Duration: {duration:.3f}s")
        print(f"    Clap at: {clap_time:.3f}s")
        print(f"    Sync offset: {offset:+.3f}s")
        print(f"    Default z_index: {default_z}")
        if 'timeline' in src and src['timeline']:
            print(f"    Timeline events: {len(src['timeline'])}")

    # Production parameters
    production = config['production']
    output_file = production['output_file']
    start_offset = float(production['start_offset'])
    end_offset = float(production['end_offset'])
    output_width = int(production.get('width', 1920))
    output_height = int(production.get('height', 1080))

    # Calculate absolute timestamps in master audio timeline
    # Offsets are relative to the clap time
    production_start = master_clap + start_offset
    production_end = master_clap + end_offset
    production_duration = production_end - production_start

    if production_duration <= 0:
        raise AVEditorError(
            f"Invalid production range: start_offset={start_offset}, end_offset={end_offset} "
            f"(duration would be {production_duration:.3f}s)")

    output_path = Path(output_file)

    print(f"\nProduction:")
    print(f"  Start offset from clap: {start_offset:+.3f}s (at {production_start:.3f}s in master audio)")
    print(f"  End offset from clap: {end_offset:+.3f}s (at {production_end:.3f}s in master audio)")
    print(f"  Duration: {production_duration:.3f}s")
    print(f"  Resolution: {output_width}x{output_height}")
    print(f"  Output file: {output_file}")

    # Check for overwrite
    if output_path.exists() and not args.force:
        raise AVEditorError(
            f"Output file exists: {output_file}\nUse --force to overwrite")

    # Build z-index timeline
    z_timeline = build_z_timeline(video_sources, master_clap, production_start, production_duration)

    if verbose:
        print(f"\n[INFO] Z-index timeline:")
        for timestamp, state in z_timeline:
            z_sorted = sorted(state.items(), key=lambda x: x[1], reverse=True)
            print(f"  {timestamp:6.2f}s: {', '.join(f'{n}={z}' for n, z in z_sorted)}")

    # Build ffmpeg command
    cmd = ['ffmpeg']

    # Add all video inputs with sync offsets adjusted for production start
    input_map = {}  # name -> input index
    for idx, (name, info) in enumerate(source_info.items()):
        # offset = how far into master audio timeline this video starts
        # We want to seek to production_start in master audio time
        # So in video time, we need: production_start - offset
        video_seek = production_start - info['offset']

        if video_seek > 0:
            # Seek into the video file
            cmd.extend(['-ss', f'{video_seek:.3f}'])

        cmd.extend(['-i', str(info['file'])])
        input_map[name] = idx

    # Add audio input, seeking to production start
    audio_idx = len(input_map)
    if production_start > 0:
        cmd.extend(['-ss', f'{production_start:.3f}'])
    cmd.extend(['-i', str(master_file)])

    # Build filter complex for overlay composition
    # Strategy: Create segments for each z-order change, then concat
    filter_parts = []

    # For each timeline segment, determine which source is on top
    segments = []
    for i in range(len(z_timeline)):
        start_time = z_timeline[i][0]
        end_time = z_timeline[i+1][0] if i+1 < len(z_timeline) else production_duration
        duration = end_time - start_time

        if duration <= 0:
            continue

        # Find source with highest z-index in this segment
        state = z_timeline[i][1]
        top_source = max(state.items(), key=lambda x: x[1])[0]

        segments.append({
            'start': start_time,
            'end': end_time,
            'duration': duration,
            'source': top_source
        })

    if verbose:
        print(f"\n[INFO] Video segments:")
        for seg in segments:
            print(f"  {seg['start']:6.2f}s - {seg['end']:6.2f}s ({seg['duration']:5.2f}s): {seg['source']}")

    # Build filter: trim each source to its segments, then concatenate
    # For now, simple approach: overlay all sources with enable expressions
    # This is inefficient but works correctly

    # Scale all sources
    for name, idx in input_map.items():
        filter_parts.append(f"[{idx}:v]scale={output_width}:{output_height}[scaled_{name}]")

    # Build enable expression for each source based on when it's on top
    source_enables = {}
    for name in input_map.keys():
        # Find all time ranges where this source is on top
        ranges = []
        for seg in segments:
            if seg['source'] == name:
                ranges.append((seg['start'], seg['end']))

        # Build enable expression: between(t, start, end) for each range
        if ranges:
            enable_exprs = [f"between(t,{start:.3f},{end:.3f})" for start, end in ranges]
            enable_expr = '+'.join(enable_exprs) if len(enable_exprs) > 1 else enable_exprs[0]
        else:
            enable_expr = "0"  # Never enabled

        source_enables[name] = enable_expr

    # Now overlay sources in order, with enable expressions
    # Start with a black background
    filter_parts.append(f"color=c=black:s={output_width}x{output_height}:d={production_duration}[bg]")

    # Overlay each source on top with its enable expression
    prev_label = 'bg'
    for i, name in enumerate(input_map.keys()):
        is_last = (i == len(input_map) - 1)
        out_label = 'out' if is_last else f'layer{i}'

        enable_expr = source_enables[name]
        filter_parts.append(
            f"[{prev_label}][scaled_{name}]overlay=0:0:enable='{enable_expr}'[{out_label}]"
        )
        prev_label = out_label

    filter_complex = ';'.join(filter_parts)

    cmd.extend([
        '-filter_complex', filter_complex,
        '-map', '[out]',
        '-map', f'{audio_idx}:a:0',
        '-t', f'{production_duration:.3f}',
        '-c:v', 'libx264',
        '-preset', 'medium',
        '-crf', '18',
        '-c:a', 'aac',
        '-b:a', '192k',
        '-movflags', '+faststart',
    ])

    # For atomic writes, use temp file
    if not args.dry_run:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        temp_fd, temp_path = tempfile.mkstemp(
            suffix=output_path.suffix,
            dir=output_path.parent,
            prefix='.av-editor-tmp-'
        )
        os.close(temp_fd)
        temp_path = Path(temp_path)
        os.chmod(temp_path, 0o644)
        target = temp_path
    else:
        target = output_path

    cmd.extend(['-y', str(target)])

    print()
    try:
        run_command(cmd, verbose=verbose, dry_run=args.dry_run)

        if not args.dry_run:
            temp_path.rename(output_path)
            print(f"\nâœ“ Rendered: {output_path}")
    except Exception:
        if not args.dry_run and temp_path.exists():
            temp_path.unlink()
        raise


def main():
    parser = argparse.ArgumentParser(
        prog='av-editor',
        description='Multi-source timeline editor with clapboard sync'
    )
    parser.add_argument('--version', action='version',
                        version=f'av-editor {VERSION}')

    subparsers = parser.add_subparsers(dest='command')

    render_parser = subparsers.add_parser(
        'render',
        help='Render synchronized output from a config file'
    )
    render_parser.add_argument('config', help='JSON config file')
    render_parser.add_argument('-v', '--verbose', action='store_true',
                               help='Show ffmpeg commands and sync details')
    render_parser.add_argument('--dry-run', action='store_true',
                               help='Show what would happen without executing')
    render_parser.add_argument('--force', action='store_true',
                               help='Overwrite output file if it exists')

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 0

    try:
        if args.command == 'render':
            render(args)
        return 0
    except AVEditorError as e:
        print(f"ERROR: {e}", file=sys.stderr)
        return 1
    except KeyboardInterrupt:
        print("\nInterrupted", file=sys.stderr)
        return 1
    except Exception as e:
        print(f"UNEXPECTED ERROR: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())
