#!/usr/bin/env python3
"""
av-editor - Multi-source timeline editor with clapboard sync

Synchronizes video and audio from multiple sources using clapboard
timestamps, with per-source timelines for z-index based compositing.

New in 0.3.x:
- production.includes (required) lets you keep only specific master-timeline ranges,
  concatenating them into the final output.
"""

import argparse
import json
import os
import re
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import Any, Dict, List, Tuple

VERSION = "0.3.0"


class AVEditorError(Exception):
    """Base exception for av-editor errors"""
    pass


def run_command(cmd, verbose=False, dry_run=False):
    """Run a command and return output"""
    if verbose or dry_run:
        # Format command for readability
        cmd_str = ' '.join(cmd)
        if len(cmd_str) > 120:
            print(f"[CMD] {cmd_str[:120]}...")
        else:
            print(f"[CMD] {cmd_str}")

    if dry_run:
        return None

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=True
        )
        return result.stdout.strip()
    except subprocess.CalledProcessError as e:
        raise AVEditorError(f"Command failed: {' '.join(cmd)}\n{e.stderr}")


def probe_duration(file_path, stream_type=None, verbose=False):
    """Get duration of a file, trying stream duration first then format"""
    if stream_type:
        cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', f'{stream_type}:0',
            '-show_entries', 'stream=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            str(file_path)
        ]
        try:
            output = run_command(cmd)
            if output and output != 'N/A':
                dur = float(output)
                if dur > 0:
                    if verbose:
                        print(f"[INFO] {Path(file_path).name}: {stream_type} stream duration = {dur:.3f}s")
                    return dur
        except (ValueError, AVEditorError):
            pass

    # Fallback to format duration
    cmd = [
        'ffprobe', '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        str(file_path)
    ]
    output = run_command(cmd)
    if output and output != 'N/A':
        dur = float(output)
        if verbose:
            print(f"[INFO] {Path(file_path).name}: format duration = {dur:.3f}s")
        return dur

    raise AVEditorError(f"Could not determine duration for {file_path}")


def probe_resolution(file_path, verbose=False):
    """Get video resolution (width, height)"""
    cmd = [
        'ffprobe', '-v', 'error',
        '-select_streams', 'v:0',
        '-show_entries', 'stream=width,height',
        '-of', 'json',
        str(file_path)
    ]
    output = run_command(cmd)
    data = json.loads(output)
    if 'streams' in data and data['streams']:
        stream = data['streams'][0]
        width = stream.get('width')
        height = stream.get('height')
        if width and height:
            return (width, height)

    raise AVEditorError(f"Could not determine resolution for {file_path}")


def validate_file(file_path):
    """Check file exists and is readable"""
    p = Path(file_path)
    if not p.exists():
        raise AVEditorError(f"File not found: {file_path}")
    if not p.is_file():
        raise AVEditorError(f"Not a file: {file_path}")
    if not os.access(p, os.R_OK):
        raise AVEditorError(f"File not readable: {file_path}")


def _is_numberish(x: Any) -> bool:
    return isinstance(x, (int, float)) or (isinstance(x, str) and x.strip() != "")


def _to_float(x: Any, ctx: str) -> float:
    if not _is_numberish(x):
        raise AVEditorError(f"{ctx} must be a number, got {type(x).__name__}")
    try:
        return float(x)
    except ValueError as e:
        raise AVEditorError(f"{ctx} must be a number, got {x!r}") from e


def _safe_label(text: str) -> str:
    """Make a string safe for ffmpeg filter labels."""
    return re.sub(r'[^0-9A-Za-z_]', '_', text)


def _validate_includes_object(includes: Any) -> None:
    """
    Validate production.includes structure.

    Required shape:
      includes: {}  (empty -> include everything)
      or:
      includes: {
        "label": [start, end],
        "label2": [[start, end], [start, end]]
      }

    Notes:
    - JSON objects can't have duplicate keys. If you want multiple ranges with the same
      label, use a list-of-ranges under that label.
    """
    if not isinstance(includes, dict):
        raise AVEditorError("production.includes must be an object (e.g. {} or {\"label\": [start,end]})")

    for label, spec in includes.items():
        # spec can be [start,end] OR [[start,end], ...]
        if not isinstance(spec, list):
            raise AVEditorError(f"production.includes.{label} must be an array")

        if len(spec) == 2 and not any(isinstance(x, list) for x in spec):
            # [start,end]
            _to_float(spec[0], f"production.includes.{label}[0]")
            _to_float(spec[1], f"production.includes.{label}[1]")
            continue

        # list-of-ranges
        if not spec:
            raise AVEditorError(f"production.includes.{label} cannot be an empty array (use {{}} for include-all)")
        for i, pair in enumerate(spec):
            if not (isinstance(pair, list) and len(pair) == 2):
                raise AVEditorError(f"production.includes.{label}[{i}] must be [start, end]")
            _to_float(pair[0], f"production.includes.{label}[{i}][0]")
            _to_float(pair[1], f"production.includes.{label}[{i}][1]")


def load_config(config_path):
    """Load and validate JSON config file"""
    validate_file(config_path)

    with open(config_path, 'r') as f:
        try:
            config = json.load(f)
        except json.JSONDecodeError as e:
            raise AVEditorError(f"Invalid JSON in {config_path}: {e}")

    # Validate required fields
    if 'master_audio' not in config:
        raise AVEditorError("Config missing 'master_audio' section")

    ma = config['master_audio']
    if 'file' not in ma:
        raise AVEditorError("master_audio missing 'file'")
    if 'clap_time' not in ma:
        raise AVEditorError("master_audio missing 'clap_time'")

    if 'video_sources' not in config or not config['video_sources']:
        raise AVEditorError("Config missing 'video_sources' (need at least one)")

    # Validate video_sources is a dict with named sources
    if not isinstance(config['video_sources'], dict):
        raise AVEditorError("video_sources must be an object with named sources")

    for name, vs in config['video_sources'].items():
        if 'file' not in vs:
            raise AVEditorError(f"video_sources.{name} missing 'file'")
        if 'clap_time' not in vs:
            raise AVEditorError(f"video_sources.{name} missing 'clap_time'")
        if 'z_index' not in vs:
            raise AVEditorError(f"video_sources.{name} missing 'z_index'")

        # Validate timeline if present
        if 'timeline' in vs:
            if not isinstance(vs['timeline'], list):
                raise AVEditorError(f"video_sources.{name}.timeline must be an array")
            for i, event in enumerate(vs['timeline']):
                if 'at' not in event:
                    raise AVEditorError(f"video_sources.{name}.timeline[{i}] missing 'at'")
                if 'z_index' not in event:
                    raise AVEditorError(f"video_sources.{name}.timeline[{i}] missing 'z_index'")

    if 'production' not in config:
        raise AVEditorError("Config missing 'production' section")

    prod = config['production']
    if 'output_file' not in prod:
        raise AVEditorError("production missing 'output_file'")
    if 'start' not in prod:
        raise AVEditorError("production missing 'start'")
    if 'end' not in prod:
        raise AVEditorError("production missing 'end'")

    # NEW: production.includes is required (can be empty {})
    if 'includes' not in prod:
        raise AVEditorError("production missing required 'includes' (use {} to include everything)")
    _validate_includes_object(prod['includes'])

    return config


def build_z_timeline(sources, master_clap, production_start, production_duration):
    """
    Build a complete z-index timeline for all sources.

    Timeline events are specified as offsets from clap time.
    We compute what the z-index state should be at production start,
    then track changes throughout the production duration.

    Returns a list of (timestamp, {source_name: z_index}) representing
    all z-index changes across all sources in production-relative time.
    """
    production_end = production_start + production_duration

    # For each source, build complete timeline in absolute master audio time
    absolute_timelines = {}
    for name, src in sources.items():
        default_z = src['z_index']
        events = [(0.0, default_z)]  # Start at beginning of master audio

        if 'timeline' in src:
            for event in src['timeline']:
                # Convert offset from clap to absolute master audio time
                absolute_time = master_clap + float(event['at'])
                events.append((absolute_time, event['z_index']))

        events.sort(key=lambda e: e[0])
        absolute_timelines[name] = events

    # Determine z-index state at production start for each source
    initial_state = {}
    for name, events in absolute_timelines.items():
        # Find the last event before or at production_start
        current_z = sources[name]['z_index']  # Default
        for timestamp, z_index in events:
            if timestamp <= production_start:
                current_z = z_index
            else:
                break
        initial_state[name] = current_z

    # Now collect all events that happen during production
    production_events = []
    for name, events in absolute_timelines.items():
        for timestamp, z_index in events:
            if production_start < timestamp <= production_end:
                # Convert to production-relative time
                prod_relative = timestamp - production_start
                production_events.append({
                    'at': prod_relative,
                    'source': name,
                    'z_index': z_index
                })

    # Sort by timestamp
    production_events.sort(key=lambda e: e['at'])

    # Build state changes timeline
    current_state = dict(initial_state)
    timeline = [(0.0, dict(current_state))]

    for event in production_events:
        current_state[event['source']] = event['z_index']
        timeline.append((event['at'], dict(current_state)))

    return timeline


def parse_includes(includes: Dict[str, Any],
                   production_start: float,
                   production_end: float,
                   verbose: bool = False) -> List[Dict[str, Any]]:
    """
    Turn production.includes into a sorted list of included segments.

    - Empty {} => include full [production_start, production_end]
    - Non-empty => include union of the specified ranges (clipped to start/end window)

    Input format:
      includes: {
        "label": [start, end],
        "label2": [[start, end], [start, end]]
      }

    Times are in absolute master-audio seconds.
    Returns: [{'label': str|None, 'start': float, 'end': float}, ...]
    """
    if includes is None:
        raise AVEditorError("production.includes is required (use {} to include everything)")
    if not isinstance(includes, dict):
        raise AVEditorError("production.includes must be an object")

    if len(includes) == 0:
        return [{
            'label': None,
            'start': production_start,
            'end': production_end
        }]

    segs: List[Dict[str, Any]] = []
    for label, spec in includes.items():
        if not isinstance(spec, list):
            raise AVEditorError(f"production.includes.{label} must be an array")

        # [start,end]
        if len(spec) == 2 and not any(isinstance(x, list) for x in spec):
            s = _to_float(spec[0], f"production.includes.{label}[0]")
            e = _to_float(spec[1], f"production.includes.{label}[1]")
            segs.append({'label': label, 'start': s, 'end': e})
            continue

        # [[start,end], ...]
        for i, pair in enumerate(spec):
            if not (isinstance(pair, list) and len(pair) == 2):
                raise AVEditorError(f"production.includes.{label}[{i}] must be [start, end]")
            s = _to_float(pair[0], f"production.includes.{label}[{i}][0]")
            e = _to_float(pair[1], f"production.includes.{label}[{i}][1]")
            segs.append({'label': label, 'start': s, 'end': e})

    # Normalize: clip to production window, drop empty, sort
    normalized: List[Dict[str, Any]] = []
    for seg in segs:
        s = seg['start']
        e = seg['end']
        if e < s:
            raise AVEditorError(
                f"Invalid includes range for label {seg['label']!r}: start {s} > end {e}"
            )

        clipped_s = max(production_start, s)
        clipped_e = min(production_end, e)

        if clipped_e <= clipped_s:
            if verbose:
                print(f"[WARN] Dropping includes range {seg['label']!r} [{s:.3f}, {e:.3f}] "
                      f"(outside production window [{production_start:.3f}, {production_end:.3f}])")
            continue

        if (clipped_s != s or clipped_e != e) and verbose:
            print(f"[INFO] Clipped includes range {seg['label']!r} [{s:.3f}, {e:.3f}] "
                  f"-> [{clipped_s:.3f}, {clipped_e:.3f}] to fit production window")

        normalized.append({'label': seg['label'], 'start': clipped_s, 'end': clipped_e})

    if not normalized:
        raise AVEditorError("production.includes produced no usable ranges (all were empty/outside start..end)")

    normalized.sort(key=lambda x: (x['start'], x['end']))

    # Merge overlaps/touching ranges to avoid accidental duplicates (labels are informational only)
    merged: List[Dict[str, Any]] = []
    for seg in normalized:
        if not merged:
            merged.append(seg)
            continue
        prev = merged[-1]
        if seg['start'] <= prev['end']:
            if seg['end'] > prev['end']:
                prev['end'] = seg['end']
        else:
            merged.append(seg)

    return merged


def _top_segments_from_z_timeline(z_timeline: List[Tuple[float, Dict[str, int]]],
                                 duration: float) -> List[Dict[str, Any]]:
    """Convert z_timeline into concrete time segments with a single top source."""
    segs: List[Dict[str, Any]] = []
    for i in range(len(z_timeline)):
        start_time = float(z_timeline[i][0])
        end_time = float(z_timeline[i + 1][0]) if i + 1 < len(z_timeline) else float(duration)
        dur = end_time - start_time
        if dur <= 0:
            continue
        state = z_timeline[i][1]
        top_source = max(state.items(), key=lambda x: x[1])[0]
        segs.append({'start': start_time, 'end': end_time, 'source': top_source})
    return segs


def _enable_expr_for_source(segments: List[Dict[str, Any]], source_name: str) -> str:
    """
    Build an ffmpeg enable expression that is true exactly when source_name is top.

    Uses half-open intervals: [start, end) to avoid double-enabling at boundaries.
    """
    ranges = [(s['start'], s['end']) for s in segments if s['source'] == source_name]
    if not ranges:
        return "0"
    parts = [f"(gte(t,{start:.3f})*lt(t,{end:.3f}))" for start, end in ranges]
    return "+".join(parts)


def render(args):
    """Render synchronized output from config"""
    config = load_config(args.config)
    verbose = args.verbose

    master = config['master_audio']
    master_file = master['file']
    master_clap = float(master['clap_time'])

    validate_file(master_file)
    master_duration = probe_duration(master_file, stream_type='a', verbose=verbose)

    print(f"Master audio: {master_file}")
    print(f"  Duration: {master_duration:.3f}s")
    print(f"  Clap at: {master_clap:.3f}s")

    # Process video sources
    video_sources = config['video_sources']
    source_info: Dict[str, Dict[str, Any]] = {}

    print(f"\nVideo sources:")
    for name, src in video_sources.items():
        file_path = src['file']
        clap_time = float(src['clap_time'])
        default_z = src['z_index']

        validate_file(file_path)
        duration = probe_duration(file_path, stream_type='v', verbose=verbose)
        width, height = probe_resolution(file_path, verbose=verbose)

        # Calculate sync offset
        # master_time = video_time + offset  =>  video_time = master_time - offset
        offset = master_clap - clap_time

        source_info[name] = {
            'file': file_path,
            'clap_time': clap_time,
            'duration': duration,
            'width': width,
            'height': height,
            'offset': offset,
            'default_z': default_z,
            'timeline': src.get('timeline', [])
        }

        print(f"  [{name}] {Path(file_path).name}")
        print(f"    Resolution: {width}x{height}")
        print(f"    Duration: {duration:.3f}s")
        print(f"    Clap at: {clap_time:.3f}s")
        print(f"    Sync offset: {offset:+.3f}s")
        print(f"    Default z_index: {default_z}")
        if 'timeline' in src and src['timeline']:
            print(f"    Timeline events: {len(src['timeline'])}")

    # Production parameters
    production = config['production']
    output_file = production['output_file']
    start = float(production['start'])
    end = float(production['end'])
    output_width = int(production.get('width', 1920))
    output_height = int(production.get('height', 1080))

    production_start = start
    production_end = end
    production_duration = production_end - production_start

    if production_duration <= 0:
        raise AVEditorError(
            f"Invalid production range: start={start}, end={end} "
            f"(duration would be {production_duration:.3f}s)")

    output_path = Path(output_file)

    # Includes (required)
    includes_obj = production.get('includes')
    include_segments = parse_includes(
        includes_obj,
        production_start=production_start,
        production_end=production_end,
        verbose=verbose
    )
    total_duration = sum(seg['end'] - seg['start'] for seg in include_segments)

    print(f"\nProduction:")
    print(f"  Window start in master audio: {production_start:.3f}s")
    print(f"  Window end in master audio:   {production_end:.3f}s")
    print(f"  Window duration:             {production_duration:.3f}s")
    print(f"  Resolution: {output_width}x{output_height}")
    print(f"  Output file: {output_file}")

    if len(include_segments) == 1 and include_segments[0]['start'] == production_start and include_segments[0]['end'] == production_end:
        print(f"  Includes: full window (production.includes is empty)")
    else:
        print(f"  Includes: {len(include_segments)} segment(s), total output duration {total_duration:.3f}s")
        for i, seg in enumerate(include_segments, 1):
            label = seg['label'] if seg['label'] is not None else ''
            print(f"    {i:2d}. {seg['start']:.3f}s - {seg['end']:.3f}s  "
                  f"({seg['end'] - seg['start']:.3f}s) {label}")

    # Check for overwrite
    if output_path.exists() and not args.force:
        raise AVEditorError(
            f"Output file exists: {output_file}\nUse --force to overwrite")

    # Build ffmpeg command
    cmd: List[str] = ['ffmpeg']

    filter_parts: List[str] = []
    seg_video_labels: List[str] = []
    seg_audio_labels: List[str] = []

    # We'll create a separate "mini render" per included segment, then concat them.
    input_index = 0
    for seg_idx, seg in enumerate(include_segments):
        seg_start = float(seg['start'])
        seg_end = float(seg['end'])
        seg_duration = seg_end - seg_start

        if verbose:
            print(f"\n[INFO] Segment {seg_idx}: master {seg_start:.3f}s - {seg_end:.3f}s ({seg_duration:.3f}s)")

        # Inputs for this segment
        seg_input_map: Dict[str, int] = {}
        seg_stream_labels: Dict[str, str] = {}   # name -> filter label for video stream post-scale/pad
        seg_delays: Dict[str, float] = {}         # name -> start pad duration when we can't seek negative

        # Add all video inputs for this segment
        for name, info in source_info.items():
            seek = seg_start - info['offset']  # desired video timestamp at segment start
            delay = 0.0
            if seek > 0:
                cmd.extend(['-ss', f'{seek:.3f}'])
            else:
                delay = -seek

            # Limit decode to segment duration
            cmd.extend(['-t', f'{seg_duration:.3f}'])
            cmd.extend(['-i', str(info['file'])])

            seg_input_map[name] = input_index
            seg_delays[name] = delay
            input_index += 1

        # Add audio input for this segment (master audio)
        if seg_start > 0:
            cmd.extend(['-ss', f'{seg_start:.3f}'])
        cmd.extend(['-t', f'{seg_duration:.3f}'])
        cmd.extend(['-i', str(master_file)])
        seg_audio_idx = input_index
        input_index += 1

        # Build z-index timeline for this segment
        z_timeline = build_z_timeline(video_sources, master_clap, seg_start, seg_duration)
        top_segments = _top_segments_from_z_timeline(z_timeline, seg_duration)

        if verbose:
            print(f"[INFO] Z-index timeline (segment {seg_idx}):")
            for ts, state in z_timeline:
                z_sorted = sorted(state.items(), key=lambda x: x[1], reverse=True)
                print(f"  {ts:6.2f}s: {', '.join(f'{n}={z}' for n, z in z_sorted)}")
            print(f"[INFO] Top-source segments (segment {seg_idx}):")
            for s in top_segments:
                print(f"  {s['start']:6.2f}s - {s['end']:6.2f}s: {s['source']}")

        # Scale all sources (+ setsar), and if needed pad start to compensate for negative seek
        for name, idx in seg_input_map.items():
            safe_name = _safe_label(name)
            base = f"seg{seg_idx}_{safe_name}"
            scaled = f"scaled_{base}"
            filter_parts.append(
                f"[{idx}:v]scale={output_width}:{output_height},setsar=1[{scaled}]"
            )

            delay = seg_delays.get(name, 0.0)
            if delay > 0.0005:
                padded = f"pad_{base}"
                filter_parts.append(
                    f"[{scaled}]tpad=start_duration={delay:.3f}:start_mode=add[{padded}]"
                )
                seg_stream_labels[name] = padded
            else:
                seg_stream_labels[name] = scaled

        # Background canvas for this segment
        bg = f"bg{seg_idx}"
        filter_parts.append(
            f"color=c=black:s={output_width}x{output_height}:d={seg_duration:.3f}[{bg}]"
        )

        # Enable expressions per source for this segment
        source_enables: Dict[str, str] = {}
        for name in seg_input_map.keys():
            source_enables[name] = _enable_expr_for_source(top_segments, name)

        # Overlay chain
        prev_label = bg
        names_in_order = list(seg_input_map.keys())
        for i, name in enumerate(names_in_order):
            is_last = (i == len(names_in_order) - 1)
            out_label = f"seg{seg_idx}_out" if is_last else f"seg{seg_idx}_layer{i}"

            enable_expr = source_enables[name]
            src_label = seg_stream_labels[name]
            filter_parts.append(
                f"[{prev_label}][{src_label}]overlay=0:0:enable='{enable_expr}'[{out_label}]"
            )
            prev_label = out_label

        # Normalize format and timestamps for concat
        v_label = f"v{seg_idx}"
        filter_parts.append(f"[{prev_label}]format=yuv420p,setpts=PTS-STARTPTS[{v_label}]")
        seg_video_labels.append(v_label)

        a_label = f"a{seg_idx}"
        filter_parts.append(
            f"[{seg_audio_idx}:a]atrim=0:{seg_duration:.3f},asetpts=PTS-STARTPTS[{a_label}]"
        )
        seg_audio_labels.append(a_label)

    # Concat segments if needed
    if len(include_segments) > 1:
        concat_in = ''.join(f"[{v}][{a}]" for v, a in zip(seg_video_labels, seg_audio_labels))
        filter_parts.append(
            f"{concat_in}concat=n={len(include_segments)}:v=1:a=1[vout][aout]"
        )
        final_v = "vout"
        final_a = "aout"
    else:
        final_v = seg_video_labels[0]
        final_a = seg_audio_labels[0]

    filter_complex = ';'.join(filter_parts)

    cmd.extend([
        '-filter_complex', filter_complex,
        '-map', f'[{final_v}]',
        '-map', f'[{final_a}]',
        '-c:v', 'libx264',
        '-preset', 'medium',
        '-crf', '18',
        '-c:a', 'aac',
        '-b:a', '192k',
        '-movflags', '+faststart',
    ])

    # For atomic writes, use temp file
    if not args.dry_run:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        temp_fd, temp_path = tempfile.mkstemp(
            suffix=output_path.suffix,
            dir=output_path.parent,
            prefix='.av-editor-tmp-'
        )
        os.close(temp_fd)
        temp_path = Path(temp_path)
        os.chmod(temp_path, 0o644)
        target = temp_path
    else:
        target = output_path

    cmd.extend(['-y', str(target)])

    print()
    try:
        run_command(cmd, verbose=verbose, dry_run=args.dry_run)

        if not args.dry_run:
            temp_path.rename(output_path)
            print(f"\nâœ“ Rendered: {output_path}")
    except Exception:
        if not args.dry_run and temp_path.exists():
            temp_path.unlink()
        raise


def main():
    parser = argparse.ArgumentParser(
        prog='av-editor',
        description='Multi-source timeline editor with clapboard sync'
    )
    parser.add_argument('--version', action='version',
                        version=f'av-editor {VERSION}')

    subparsers = parser.add_subparsers(dest='command')

    render_parser = subparsers.add_parser(
        'render',
        help='Render synchronized output from a config file'
    )
    render_parser.add_argument('config', help='JSON config file')
    render_parser.add_argument('-v', '--verbose', action='store_true',
                               help='Show ffmpeg commands and sync details')
    render_parser.add_argument('--dry-run', action='store_true',
                               help='Show what would happen without executing')
    render_parser.add_argument('--force', action='store_true',
                               help='Overwrite output file if it exists')

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 0

    try:
        if args.command == 'render':
            render(args)
        return 0
    except AVEditorError as e:
        print(f"ERROR: {e}", file=sys.stderr)
        return 1
    except KeyboardInterrupt:
        print("\nInterrupted", file=sys.stderr)
        return 1
    except Exception as e:
        print(f"UNEXPECTED ERROR: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())
